{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flickr30k-CN统计\n",
    "Flickr30k-CN数据集下载：https://aistudio.baidu.com/datasetdetail/210101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "flickr_data_path = \"datasets/Flicker30k_Dataset/\"\n",
    "flickr_anno_path = \"datasets/Flickr30k-CNA/\"\n",
    "\n",
    "train_label = os.path.join(flickr_anno_path, \"train\", \"flickr30k_cna_train.txt\")\n",
    "test_label = os.path.join(flickr_anno_path, \"test\", \"flickr30k_cn_test.txt\")\n",
    "val_label = os.path.join(flickr_anno_path, \"val\", \"flickr30k_cna_val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 图片总数：31783张\n",
      "=> train: 148909张\n",
      "=> test: 5000张\n",
      "=> val: 5000张\n"
     ]
    }
   ],
   "source": [
    "# 数据统计\n",
    "\n",
    "img_list = glob.glob(f\"{flickr_data_path}*.jpg\")\n",
    "total_num = len(img_list) #31783条\n",
    "print(f\"=> 图片总数：{total_num}张\")\n",
    "\n",
    "with open(train_label, encoding='utf-8') as f:\n",
    "    train_label_list = f.readlines()\n",
    "    print(f\"=> train: {len(train_label_list)}张\")\n",
    "\n",
    "with open(test_label, encoding='utf-8') as f:\n",
    "    test_label_list = f.readlines()\n",
    "    print(f\"=> test: {len(test_label_list)}张\")\n",
    "    \n",
    "with open(val_label, encoding='utf-8') as f:\n",
    "    val_label_list = f.readlines()\n",
    "    print(f\"=> val: {len(val_label_list)}张\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N张子集抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 1: \tdatasets/Flicker30k_Dataset/1312954382.jpg\n",
      "==> 2: \tdatasets/Flicker30k_Dataset/1313693129.jpg\n",
      "==> 3: \tdatasets/Flicker30k_Dataset/1313869424.jpg\n",
      "==> 4: \tdatasets/Flicker30k_Dataset/1313961775.jpg\n",
      "==> 5: \tdatasets/Flicker30k_Dataset/1313987366.jpg\n",
      "==> 6: \tdatasets/Flicker30k_Dataset/1314231418.jpg\n",
      "==> 7: \tdatasets/Flicker30k_Dataset/1315116409.jpg\n",
      "==> 8: \tdatasets/Flicker30k_Dataset/131624221.jpg\n",
      "==> 9: \tdatasets/Flicker30k_Dataset/1316247213.jpg\n",
      "==> 10: \tdatasets/Flicker30k_Dataset/131632409.jpg\n",
      "==> 10张图\n"
     ]
    }
   ],
   "source": [
    "# 抽取val集中前N张图和标注\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# 多少图片\n",
    "NUM = 10\n",
    "\n",
    "# 输出目录\n",
    "NEW_DATASET = f\"assets/Flickr{NUM}/\"\n",
    "LABEL_FILE = NEW_DATASET + \"label.txt\" # 标签文件\n",
    "try:\n",
    "    os.makedirs(NEW_DATASET, mode=0o777, exist_ok=False)\n",
    "    with open(LABEL_FILE, 'a') as file:\n",
    "        i = 1\n",
    "        tmp = []\n",
    "        \n",
    "        for line in train_label_list:\n",
    "            \n",
    "            # 1315402173\t一个小男孩在检查一片南瓜地，他的手推车里已经有一些南瓜了。        \n",
    "            if len(line_sp := line.split(\"\\t\")) == 2:\n",
    "                \n",
    "                # 写标签文件\n",
    "                file.write(line)  # 写入内容并换行\n",
    "                \n",
    "                # 复制图片文件\n",
    "                img = f\"{flickr_data_path}{line_sp[0]}.jpg\"\n",
    "                if img not in tmp:\n",
    "                    cmd = f\"cp {img} {NEW_DATASET}\"\n",
    "                    res = subprocess.call(cmd, shell=True)\n",
    "                    print(f\"==> {i}: \\t{img}\")\n",
    "                    \n",
    "                    if i == NUM:\n",
    "                        break\n",
    "                    \n",
    "                    i += 1\n",
    "                    tmp.append(img)\n",
    "except FileExistsError as e:\n",
    "    print(e)\n",
    "\n",
    "IMG_LIST = glob.glob(f\"{NEW_DATASET}*.jpg\")\n",
    "print(f\"==> {len(IMG_LIST)}张图\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征向量批量提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `AltCLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "2023-09-07 15:25:47.356682: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 15:25:47.507451: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-07 15:25:48.065613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.5/lib64:\n",
      "2023-09-07 15:25:48.065680: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.5/lib64:\n",
      "2023-09-07 15:25:48.065683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "`vision_config_dict` is provided which will be used to initialize `ChineseCLIPVisionConfig`. The value `vision_config[\"model_type\"]` will be overriden.\n",
      "`vision_config_dict` is provided which will be used to initialize `ChineseCLIPVisionConfig`. The value `vision_config[\"model_type\"]` will be overriden.\n",
      "`vision_config_dict` is provided which will be used to initialize `ChineseCLIPVisionConfig`. The value `vision_config[\"model_type\"]` will be overriden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 开始提取：assets/Flickr10/\n",
      "==> 10张图\n",
      "==> 完成写入：assets/Flickr10_image_list.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 768)\n",
      "==> 完成写入：assets/Flickr10_altclip.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 768)\n",
      "==> 完成写入：assets/Flickr10_cnclip.npy\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from utils.altclip import AltCLIP\n",
    "from utils.cnclip import CNCLIP\n",
    "\n",
    "altclip = AltCLIP(\"/mnt/data/CLIP/models/AltCLIP\", \"cuda:0\")\n",
    "cnclip = CNCLIP(\"/mnt/data/CLIP/models/chinese-clip-vit-large-patch14\", \"cuda:1\")\n",
    "\n",
    "print(f\"==> 开始提取：{NEW_DATASET}\")\n",
    "IMG_LIST = glob.glob(f\"{NEW_DATASET}*.jpg\")\n",
    "print(f\"==> {len(IMG_LIST)}张图\")\n",
    "\n",
    "# 图像路径保存txt文件\n",
    "with open(f\"assets/Flickr{NUM}_image_list.txt\", 'w') as f: #\"w\"覆盖写入，\"a\"追加写入，r只读\n",
    "    f.write('\\n'.join(IMG_LIST))\n",
    "print(f\"==> 完成写入：assets/Flickr{NUM}_image_list.txt\")\n",
    "\n",
    "# 批处理特征提取\n",
    "def img_feat_ext(IMG_LIST, clip_type):\n",
    "    \n",
    "    img_768_emb_list = np.empty((0, 768)).astype('float32')\n",
    "    \n",
    "    for img_path in tqdm(IMG_LIST):\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if clip_type == \"altclip\":\n",
    "            img_768_emb = altclip(img, txt=None)[0]\n",
    "            img_768_emb_list = np.append(img_768_emb_list, img_768_emb, axis=0)\n",
    "            \n",
    "        if clip_type == \"cnclip\":\n",
    "            img_768_emb = cnclip(img, txt=None)[0]\n",
    "            img_768_emb_list = np.append(img_768_emb_list, img_768_emb, axis=0)\n",
    "        \n",
    "    print(img_768_emb_list.shape)\n",
    "    return img_768_emb_list\n",
    "\n",
    "# 图像特征提取并保存npy文件\n",
    "CLIP_IDS = [\"altclip\", \"cnclip\"]\n",
    "for clip_id in CLIP_IDS:\n",
    "    np.save(f\"assets/Flickr{NUM}_{clip_id}.npy\", img_feat_ext(IMG_LIST, clip_type=clip_id))\n",
    "    print(f\"==> 完成写入：assets/Flickr{NUM}_{clip_id}.npy\")\n",
    "\n",
    "del altclip, cnclip\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
